{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text 简单清洗\n",
    "import re\n",
    "\n",
    "def remove_non_english(text):\n",
    "    # Only keep ASCII letters, numbers, punctuation, apostrophes, and whitespace\n",
    "    pattern = re.compile(r'[^\\x00-\\x7F]+[\\W_]?')\n",
    "    # Remove non-English characters\n",
    "    clean_text = pattern.sub('', text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_json = \"data/tracking_out_ocr_v3.json\"\n",
    "output_json = \"data/tracking_out_ocr__v3_clean.json\"\n",
    "\n",
    "with open (input_json, 'r') as load_data:\n",
    "    texts = json.load(load_data)\n",
    "for idx, text in texts.items():\n",
    "    texts[idx] = remove_non_english(text)\n",
    "\n",
    "with open (output_json, 'w') as data:\n",
    "    json.dump(texts, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text 内容补充，拼接音频识别信息\n",
    "from similarity.normalized_levenshtein import NormalizedLevenshtein\n",
    "\n",
    "THRESHOULD = 0.3\n",
    "def is_speech_correct(video_text, speech_text):\n",
    "    normalized_levenshtein = NormalizedLevenshtein()\n",
    "    ans = normalized_levenshtein.similarity(video_text, speech_text)\n",
    "    if ans >= THRESHOULD:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text 二次处理, seq2seq 重写text\n",
    "import os\n",
    "import openai\n",
    "from time import sleep\n",
    "def improve_text(origin_text):\n",
    "    sleep(3)\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    # res = openai.Edit.create(\n",
    "    # model=\"text-davinci-edit-001\",\n",
    "    # input=origin_text,\n",
    "    # instruction=\"Fix the OCR errors\",\n",
    "    # n=3,\n",
    "    # temperature=0.8\n",
    "    # )\n",
    "    if len(origin_text) > 8000:\n",
    "        origin_text = origin_text[:8000]\n",
    "    prompt = \"\"\"\n",
    "    The following text contains some OCR recognition errors and duplicate content when merging video frames.\n",
    "    Now you need to:\n",
    "    1. Correct the mistakes in words.\n",
    "    2. Correct the grammatical errors in the text.\n",
    "    3. When the paragraphs contain repeated sentences or similar sentences, please summarize this part.\n",
    "    Note that all modifications keep the original vocabulary as much as possible, do not add new vocabulary when modifying.\n",
    "   \n",
    "    If all the above modifications are not possible for you, please output the original text.\n",
    "    \n",
    "    For example:\n",
    "    Origin context: Thenmodellis very precise,lis very preciseis very preciseThenmodel ,Thenmodel is very precise,100%high o ualitysoft material,3\\uff1a02, ualitysoft material100%high o uality100%high o ,100%high o uality soft material,ycarcary,\\u7eff\\u8272Green,y\\u7070\\u8272Gra\\u7070\\u8272Grav,\\u7c89\\u8272Pink,\\u68d5\\u8272Brown,\\u7ea2\\u8272Red,\\u84dd\\u8272Blue,\\u7d2b\\u8272Purple,\\u73ab\\u7470\\u91d1Rose gold\n",
    "    \n",
    "    Rewritten context: The model is very precise. 100% high quality soft material. Easy to carry. Green, Gray, Pink, Brown, Red, Blue, Purple, Rose gold.\n",
    "    \n",
    "    Now, your turn:\n",
    "    Origin context: {0}\n",
    "\n",
    "    Rewritten context:\n",
    "    \"\"\".format(origin_text)\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': prompt},\n",
    "    ],\n",
    "    temperature=0.5,\n",
    ")\n",
    "    new_text = origin_text\n",
    "    try:\n",
    "        # new_text = res['choices'][0]['text']\n",
    "        new_text = response['choices'][0]['message']['content']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return new_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Live the life you love. Don't just exist, but truly live. Follow your passions and do what makes you happy. Embrace the life you have and make the most of it.\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improve_text(\"the,Livelhe,ileyoulove,nlove,Live the,thelife,ifeyou,Livethelifeyou loy,Livethe life youlove,Livethe life vou love,the lile youlove,Live theliteyou love,Live the lireyou,Livethe,Livet,ulove,11,thefeyuulove,olove,Livethelileyoulove,Live the life you love,Live the life,iove,L.ive the life yo,Live thet,Live thelifeyou love,ivethelifeyou love,thelifl,Yau love,helileyoulove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [32:19<00:00,  7.76s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "def gpt_improve_text(PATH,RES_PATH):\n",
    "    with open(PATH, 'r') as load_data:\n",
    "        texts = json.load(load_data)\n",
    "    for idx, text in tqdm(texts.items()):\n",
    "        texts[idx] = improve_text(text)\n",
    "    with open (RES_PATH, 'w') as data:\n",
    "        json.dump(texts, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/tracking_out_ocr__v2_clean.json', 'r') as load_data:\n",
    "    texts = json.load(load_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [32:20<00:00,  7.76s/it] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for idx, text in tqdm(texts.items()):\n",
    "    if idx not in count_set:\n",
    "        texts[idx] = improve_text(text)\n",
    "        count_set.add(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"data/tracking_out_ocr_gpt3.5_v4.json\", 'w') as data:\n",
    "    json.dump(texts, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchwithgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
